{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "machine-translation-with-trax.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyPyV0Bz1fS5OJPnY/v7LQNY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rahiakela/transformers-for-natural-language-processing/blob/main/5-machine-translation-with-transformer/machine_translation_with_trax.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gkvHDHhDI-hB"
      },
      "source": [
        "##Machine Translation with Trax"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "apkfEhWBJMyt"
      },
      "source": [
        "Google Brain produced Trax, an end-to-end deep learning library. Trax contains a transformer model that can be applied to translations. The Google Brain team presently maintains Trax.\n",
        "\n",
        "We will be using preprocessed English and German datasets to show that the\n",
        "Transformer architecture is language-agnostic.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cdS2FKVZUVaG"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bYKjDb37UaZA"
      },
      "source": [
        "!pip install -q -U trax"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cdLfEaldUXI_"
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import trax"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0D_EItSZUhu6"
      },
      "source": [
        "## Creating a Transformer model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ZImKikIUiq8"
      },
      "source": [
        "We will create the original Transformer model.\n",
        "\n",
        "Our Trax function will retrieve a pretrained model configuration in a few lines of code:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "69OJva09UuKT"
      },
      "source": [
        "model = trax.models.Transformer(\n",
        "    input_vocab_size=33300,\n",
        "    d_model=512,\n",
        "    d_ff=2048,\n",
        "    n_heads=8, \n",
        "    n_encoder_layers=6,\n",
        "    n_decoder_layers=6,\n",
        "    max_len=2048,\n",
        "    mode=\"predict\"\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bniD2Qz5VVPk"
      },
      "source": [
        "The model is the Transformer with an encoder and decoder stack. Each stack\n",
        "contains 6 layers and 8 heads. d_model=512 as in the architecture of the original Transformer.\n",
        "\n",
        "The Transformer requires the pretrained weights to run."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0tXtoVdZVaOA"
      },
      "source": [
        "## Initializing the model using pretrained weights"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n6qyBIw_VbCt"
      },
      "source": [
        "The pretrained weights contain the intelligence of the Transformer. The weights constitute the Transformer's representation of language. The weights can be expressed as a number of parameters that will produce some form of machine intelligence IQ.\n",
        "\n",
        "Let's give life to the model by initializing the weights:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vSkjRVQYVQs2"
      },
      "source": [
        "model.init_from_file(\"gs://trax-ml/models/translation/ende_wmt32k.pkl.gz\", weights_only=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "37oa__PgV0JE"
      },
      "source": [
        "The machine configuration and its intelligence are now ready to run. Let's tokenize a sentence."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oYy7qD2iV2GX"
      },
      "source": [
        "##Tokenizing a sentence"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pk5qy8nBV4is"
      },
      "source": [
        "Our machine translator is ready to tokenize a sentence. The preprocessing method is similar to the one described in the Preprocessing a WMT dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kiIYxo0NVwBV"
      },
      "source": [
        "sentence = \"I am only a machine but I have machine intelligence.\"\n",
        "\n",
        "tokenized = list(trax.data.tokenize(iter([sentence]),\n",
        "                                    vocab_dir=\"gs://trax-ml/vocabs/\",\n",
        "                                    vocab_file=\"ende_32k.subword\"))[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ufT0fsdsW5MT"
      },
      "source": [
        "The program will now decode the sentence and produce a translation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "amKzH5XxW6Zj"
      },
      "source": [
        "## Decoding from the Transformer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "608Aeg3FW9NU"
      },
      "source": [
        "The Transformer encodes the sentence in English and will decode it in German. The model and its weights constitute its set of abilities."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OhIPjgNcXEbM"
      },
      "source": [
        "tokenized = tokenized[None, :]  # Add batch dimension\n",
        "\n",
        "# Higher temperature: more diverse results.\n",
        "tokenized_translation = trax.supervised.decoding.autoregressive_sample(model, tokenized, temperature=0.0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oz3I85nTYXgR"
      },
      "source": [
        "Note that higher temperatures will produce diverse results just as with human\n",
        "translators.\n",
        "\n",
        "Finally, the program will de-tokenize and display the translation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YE7vSFk5YeNX"
      },
      "source": [
        "## De-tokenizing and displaying the translation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5mVYBTaWYfKF"
      },
      "source": [
        "Google Brain has produced a mainstream, disruptive, and intuitive implementation of the Transformer with Trax.\n",
        "\n",
        "The program now de-tokenizes and displays the translation in a few lines:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K1Ihd-t8YWvF",
        "outputId": "b379e95c-c52e-439f-ec6b-1a1cb0656e7d"
      },
      "source": [
        "tokenized_translation = tokenized_translation[0][:-1]  # Remove batch and EOS.\n",
        "\n",
        "translation = trax.data.detokenize(tokenized_translation,\n",
        "                                   vocab_dir=\"gs://trax-ml/vocabs/\",\n",
        "                                   vocab_file=\"ende_32k.subword\")\n",
        "\n",
        "print(\"The sentence:\", sentence)\n",
        "print(\"The translation:\", translation)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The sentence: I am only a machine but I have machine intelligence.\n",
            "The translation: Ich bin nur eine Maschine, aber ich habe Maschinenübersicht.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CmixIhDpZnmV"
      },
      "source": [
        "The Transformer translated \"machine intelligence\" into \"Maschinübersicht.\"\n",
        "\n",
        "The Transformer is telling us that although it is a machine, it has vision. Machine intelligence is growing through Transformers, but it is not human intelligence. Machines learn languages with an intelligence of their own."
      ]
    }
  ]
}