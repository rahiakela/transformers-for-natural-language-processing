{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "semantic-role-labeling.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rahiakela/transformers-for-natural-language-processing/blob/main/9-semantic-role-labeling-with-bert-based-transformers/semantic_role_labeling.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bzRpKWxSgZmb"
      },
      "source": [
        "##Semantic Role Labeling(SRL)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PV7xU4RgFRKq"
      },
      "source": [
        "We will run our SRL experiments using the BERT SRL. We will begin with basic samples with various sentence structures. We will then challenge the BERT-based model with some more difficult samples to explore the system's capacity and limits.\n",
        "\n",
        "The notebook is an implementation of the Allen Institute for AI BERT-based model. [Reference usage of the Notebook](https://demo.allennlp.org/semantic-role-labeling/MjE4NjI1Ng==)\n",
        "\n",
        "The BERT-based model is an implementation of [Peng Shi and Jimmy Lin, (2019), ‘Simple BERT Models for Relation Extraction and Semantic Role Labeling’]( https://arxiv.org/abs/1904.05255)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9aeqrxgQhKmE"
      },
      "source": [
        "Intalling Allen NLP"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XAIkwYFaeBBD"
      },
      "source": [
        "!pip install allennlp==1.0.0 allennlp-models==1.0.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7WQOBRkgFu7c"
      },
      "source": [
        "##Basic samples"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Ssmk0XsFvzz"
      },
      "source": [
        "Basic samples seem intuitively simple but can be tricky to analyze. Compound\n",
        "sentences, adjectives, adverbs, and modals are not easy to identify, even for nonexpert humans.\n",
        "\n",
        "Let's begin with an easy sample for the transformer."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "17kQ3f_2GErw"
      },
      "source": [
        "###Sample 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EcSZJu8ohUv5"
      },
      "source": [
        "The first sample is long but relatively easy for the transformer:\n",
        "\n",
        "``` Did Bob really think he could prepare a meal for 50 people in only a few hours?```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Qznb_bdI2CS",
        "outputId": "e687a61c-a9b1-4f3c-a118-8ca487a7f4ad"
      },
      "source": [
        "!echo '{\"sentence\": \"Did Bob really think he could prepare a meal for 50 people in only a few hours?\"}' | \\\n",
        "allennlp predict https://storage.googleapis.com/allennlp-public-models/bert-base-srl-2020.03.24.tar.gz -"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "input 0:  {\"sentence\": \"Did Bob really think he could prepare a meal for 50 people in only a few hours?\"}\n",
            "prediction:  {\"verbs\": [{\"verb\": \"think\", \"description\": \"Did [ARG0: Bob] [ARGM-ADV: really] [V: think] [ARG1: he could prepare a meal for 50 people in only a few hours] ?\", \"tags\": [\"O\", \"B-ARG0\", \"B-ARGM-ADV\", \"B-V\", \"B-ARG1\", \"I-ARG1\", \"I-ARG1\", \"I-ARG1\", \"I-ARG1\", \"I-ARG1\", \"I-ARG1\", \"I-ARG1\", \"I-ARG1\", \"I-ARG1\", \"I-ARG1\", \"I-ARG1\", \"I-ARG1\", \"O\"]}, {\"verb\": \"could\", \"description\": \"Did Bob really think he [V: could] prepare a meal for 50 people in only a few hours ?\", \"tags\": [\"O\", \"O\", \"O\", \"O\", \"O\", \"B-V\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\"]}, {\"verb\": \"prepare\", \"description\": \"Did Bob really think [ARG0: he] [ARGM-MOD: could] [V: prepare] [ARG1: a meal for 50 people] [ARGM-TMP: in only a few hours] ?\", \"tags\": [\"O\", \"O\", \"O\", \"O\", \"B-ARG0\", \"B-ARGM-MOD\", \"B-V\", \"B-ARG1\", \"I-ARG1\", \"I-ARG1\", \"I-ARG1\", \"I-ARG1\", \"B-ARGM-TMP\", \"I-ARGM-TMP\", \"I-ARGM-TMP\", \"I-ARGM-TMP\", \"I-ARGM-TMP\", \"O\"]}], \"words\": [\"Did\", \"Bob\", \"really\", \"think\", \"he\", \"could\", \"prepare\", \"a\", \"meal\", \"for\", \"50\", \"people\", \"in\", \"only\", \"a\", \"few\", \"hours\", \"?\"]}\n",
            "\n",
            "2021-06-21 05:55:45,979 - INFO - allennlp.models.archival - removing temporary unarchived model dir at /tmp/tmpnbilm10n\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dv9kRqs0JNri"
      },
      "source": [
        "If we take a close look at this representation, we can detect some interesting\n",
        "properties of the simple BERT-based transformer, which:\n",
        "\n",
        "- Detected the verb \"think\"\n",
        "- Avoided the \"prepare\" trap that could have been interpreted as the main\n",
        "verb. Instead, \"prepare\" remained part of the argument of \"think\"\n",
        "- Detected an adverb and labeled it"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qes0KqqhJZul"
      },
      "source": [
        "###Sample 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hWHpOrNvZQ3m"
      },
      "source": [
        "The following sentence seems easy but contains several verbs:\n",
        "\n",
        "```Mrs. and Mr. Tomaso went to Europe for vacation and visited Paris and first went to visit the Eiffel Tower.```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yFKPLyqihrB_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "59abb91a-5da9-4490-a925-35d2fdea96f6"
      },
      "source": [
        "!echo '{\"sentence\": \"Mrs. and Mr. Tomaso went to Europe for vacation and visited Paris and first went to visit the Eiffel Tower.\"}' | \\\n",
        "allennlp predict https://storage.googleapis.com/allennlp-public-models/bert-base-srl-2020.03.24.tar.gz -"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "input 0:  {\"sentence\": \"Mrs. and Mr. Tomaso went to Europe for vacation and visited Paris and first went to visit the Eiffel Tower.\"}\n",
            "prediction:  {\"verbs\": [{\"verb\": \"went\", \"description\": \"[ARG0: Mrs. and Mr. Tomaso] [V: went] [ARG4: to Europe] [ARGM-PRP: for vacation] and visited Paris and first went to visit the Eiffel Tower .\", \"tags\": [\"B-ARG0\", \"I-ARG0\", \"I-ARG0\", \"I-ARG0\", \"B-V\", \"B-ARG4\", \"I-ARG4\", \"B-ARGM-PRP\", \"I-ARGM-PRP\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\"]}, {\"verb\": \"visited\", \"description\": \"[ARG0: Mrs. and Mr. Tomaso] went to Europe for vacation and [V: visited] [ARG1: Paris] and first went to visit the Eiffel Tower .\", \"tags\": [\"B-ARG0\", \"I-ARG0\", \"I-ARG0\", \"I-ARG0\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"B-V\", \"B-ARG1\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\"]}, {\"verb\": \"went\", \"description\": \"[ARG0: Mrs. and Mr. Tomaso] went to Europe for vacation and visited Paris and [ARGM-TMP: first] [V: went] [ARGM-PRP: to visit the Eiffel Tower] .\", \"tags\": [\"B-ARG0\", \"I-ARG0\", \"I-ARG0\", \"I-ARG0\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"B-ARGM-TMP\", \"B-V\", \"B-ARGM-PRP\", \"I-ARGM-PRP\", \"I-ARGM-PRP\", \"I-ARGM-PRP\", \"I-ARGM-PRP\", \"O\"]}, {\"verb\": \"visit\", \"description\": \"[ARG0: Mrs. and Mr. Tomaso] went to Europe for vacation and visited Paris and first went to [V: visit] [ARG1: the Eiffel Tower] .\", \"tags\": [\"B-ARG0\", \"I-ARG0\", \"I-ARG0\", \"I-ARG0\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"B-V\", \"B-ARG1\", \"I-ARG1\", \"I-ARG1\", \"O\"]}], \"words\": [\"Mrs.\", \"and\", \"Mr.\", \"Tomaso\", \"went\", \"to\", \"Europe\", \"for\", \"vacation\", \"and\", \"visited\", \"Paris\", \"and\", \"first\", \"went\", \"to\", \"visit\", \"the\", \"Eiffel\", \"Tower\", \".\"]}\n",
            "\n",
            "2021-06-21 05:58:41,273 - INFO - allennlp.models.archival - removing temporary unarchived model dir at /tmp/tmpdpd3ktvq\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yQC6OLMXJ3a9"
      },
      "source": [
        "We can interpret the arguments of the verb \"went.\" However, the transformer found that the modifier of the verb was the purpose of the trip.\n",
        "\n",
        "We can also notice that \"went\" was correctly associated with \"Europe\". The\n",
        "transformer correctly identified the verb \"visit\" as being related to \"Paris\".\n",
        "\n",
        "The transformer could have associated the verb \"visited\" directly with the \"Eiffel Tower\". But it didn't. It stood its ground and made the right decision.\n",
        "\n",
        "The verb \"went\" was used twice, but the transformer did not fall into the trap. It even found that \"first\" was a temporal modifier of the verb \"went.\"\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-DMmni6RLlug"
      },
      "source": [
        "###Sample 3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v45ooI5ReoXk"
      },
      "source": [
        "Now we will will make things more difficult for our transformer model. The following sample contains the verb \"drink\" four times:\n",
        "\n",
        "```John wanted to drink tea, Mary likes to drink coffee but Karim drank some cool water and Faiza would like to drink tomato juice.```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pz-jLVeAersa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "15b33686-5c66-4791-f12e-ea18cf32366f"
      },
      "source": [
        "!echo '{\"sentence\": \"John wanted to drink tea, Mary likes to drink coffee but Karim drank some cool water and Faiza would like to drink tomato juice.\"}' | \\\n",
        "allennlp predict https://storage.googleapis.com/allennlp-public-models/bert-base-srl-2020.03.24.tar.gz -"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "input 0:  {\"sentence\": \"John wanted to drink tea, Mary likes to drink coffee but Karim drank some cool water and Faiza would like to drink tomato juice.\"}\n",
            "prediction:  {\"verbs\": [{\"verb\": \"wanted\", \"description\": \"[ARG0: John] [V: wanted] [ARG1: to drink tea] , Mary likes to drink coffee but Karim drank some cool water and Faiza would like to drink tomato juice .\", \"tags\": [\"B-ARG0\", \"B-V\", \"B-ARG1\", \"I-ARG1\", \"I-ARG1\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\"]}, {\"verb\": \"drink\", \"description\": \"[ARG0: John] wanted to [V: drink] [ARG1: tea] , Mary likes to drink coffee but Karim drank some cool water and Faiza would like to drink tomato juice .\", \"tags\": [\"B-ARG0\", \"O\", \"O\", \"B-V\", \"B-ARG1\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\"]}, {\"verb\": \"likes\", \"description\": \"John wanted to drink tea , [ARG0: Mary] [V: likes] [ARG1: to drink coffee] but Karim drank some cool water and Faiza would like to drink tomato juice .\", \"tags\": [\"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"B-ARG0\", \"B-V\", \"B-ARG1\", \"I-ARG1\", \"I-ARG1\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\"]}, {\"verb\": \"drink\", \"description\": \"John wanted to drink tea , [ARG0: Mary] likes to [V: drink] [ARG1: coffee] but Karim drank some cool water and Faiza would like to drink tomato juice .\", \"tags\": [\"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"B-ARG0\", \"O\", \"O\", \"B-V\", \"B-ARG1\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\"]}, {\"verb\": \"drank\", \"description\": \"John wanted to drink tea , Mary likes to drink coffee but [ARG0: Karim] [V: drank] [ARG1: some cool water and Faiza] would like to drink tomato juice .\", \"tags\": [\"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"B-ARG0\", \"B-V\", \"B-ARG1\", \"I-ARG1\", \"I-ARG1\", \"I-ARG1\", \"I-ARG1\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\"]}, {\"verb\": \"would\", \"description\": \"John wanted to drink tea , Mary likes to drink coffee but Karim drank some cool water and Faiza [V: would] [ARGM-DIS: like] to drink tomato juice .\", \"tags\": [\"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"B-V\", \"B-ARGM-DIS\", \"O\", \"O\", \"O\", \"O\", \"O\"]}, {\"verb\": \"like\", \"description\": \"John wanted to drink tea , Mary likes to drink coffee but Karim drank [ARG0: some cool water and Faiza] [ARGM-MOD: would] [V: like] [ARG1: to drink tomato juice] .\", \"tags\": [\"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"B-ARG0\", \"I-ARG0\", \"I-ARG0\", \"I-ARG0\", \"I-ARG0\", \"B-ARGM-MOD\", \"B-V\", \"B-ARG1\", \"I-ARG1\", \"I-ARG1\", \"I-ARG1\", \"O\"]}, {\"verb\": \"drink\", \"description\": \"John wanted to drink tea , Mary likes to drink coffee but Karim drank [ARG0: some cool water and Faiza] would like to [V: drink] [ARG1: tomato juice] .\", \"tags\": [\"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"B-ARG0\", \"I-ARG0\", \"I-ARG0\", \"I-ARG0\", \"I-ARG0\", \"O\", \"O\", \"O\", \"B-V\", \"B-ARG1\", \"I-ARG1\", \"O\"]}], \"words\": [\"John\", \"wanted\", \"to\", \"drink\", \"tea\", \",\", \"Mary\", \"likes\", \"to\", \"drink\", \"coffee\", \"but\", \"Karim\", \"drank\", \"some\", \"cool\", \"water\", \"and\", \"Faiza\", \"would\", \"like\", \"to\", \"drink\", \"tomato\", \"juice\", \".\"]}\n",
            "\n",
            "2021-06-21 06:08:45,932 - INFO - allennlp.models.archival - removing temporary unarchived model dir at /tmp/tmpes86tz9o\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bvI7eFUtL7sS"
      },
      "source": [
        "The first one is perfect. it identifies the verb \"wanted\" and makes the right\n",
        "associations.\n",
        "\n",
        "However, when it identified the verb \"drank,\" it slipped in \"and Faiza\" as an\n",
        "argument.\n",
        "\n",
        "The sentence meant that \"Karim drank some cool water.\" The presence of \"and\n",
        "Faiza\" as an argument of \"drank\" is debatable.\n",
        "\n",
        "The presence of \"some cool water and\" is not an argument of like. Only \"Faiza\" is an argument of \"like.\". The output is a bit fuzzy."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9lHv3Hq6MWoI"
      },
      "source": [
        "##Difficult samples"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tzjaDPghMXfI"
      },
      "source": [
        "Now, we will run samples that contain problems that the BERT-based\n",
        "transformer will first solve. We will end with an intractable sample.\n",
        "\n",
        "Let's start with a complex sample that the BERT-based transformer can analyze."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s8WKhxfCMikp"
      },
      "source": [
        "###Sample 4"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k7QVm45YmxTt"
      },
      "source": [
        "It takes us into more tricky SRL territory. The sample separates \"Alice\" from\n",
        "the verb \"liked,\" creating a long-term dependency that has to jump over \"whose\n",
        "husband went jogging every Sunday.\"\n",
        "\n",
        "The sentence is:\n",
        "\n",
        "```Alice, whose husband went jogging every Sunday, liked to go to a dancing class in the meantime.```\n",
        "\n",
        "A human can isolate \"Alice\" and find the predicate:\n",
        "\n",
        "```\n",
        "[Alice, whose husband went jogging every Sunday], liked to go to a dancing\n",
        "class in the meantime.```\n",
        "\n",
        "Can the BERT model find the predicate like us?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mvm6zN7_m0GI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5d5fd903-4848-4969-aca1-8b10934d8e16"
      },
      "source": [
        "!echo '{\"sentence\": \"Alice, whose husband went jogging every Sunday, liked to go to a dancing class in the meantime.\"}' | \\\n",
        "allennlp predict https://storage.googleapis.com/allennlp-public-models/bert-base-srl-2020.03.24.tar.gz -"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "input 0:  {\"sentence\": \"Alice, whose husband went jogging every Sunday, liked to go to a dancing class in the meantime.\"}\n",
            "prediction:  {\"verbs\": [{\"verb\": \"went\", \"description\": \"Alice , [ARG1: whose husband] [V: went] [ARG2: jogging] [ARGM-TMP: every Sunday] , liked to go to a dancing class in the meantime .\", \"tags\": [\"O\", \"O\", \"B-ARG1\", \"I-ARG1\", \"B-V\", \"B-ARG2\", \"B-ARGM-TMP\", \"I-ARGM-TMP\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\"]}, {\"verb\": \"jogging\", \"description\": \"Alice , [ARG0: whose husband] went [V: jogging] [ARGM-TMP: every Sunday] , liked to go to a dancing class in the meantime .\", \"tags\": [\"O\", \"O\", \"B-ARG0\", \"I-ARG0\", \"O\", \"B-V\", \"B-ARGM-TMP\", \"I-ARGM-TMP\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\"]}, {\"verb\": \"liked\", \"description\": \"[ARG0: Alice , whose husband went jogging every Sunday] , [V: liked] [ARG1: to go to a dancing class in the meantime] .\", \"tags\": [\"B-ARG0\", \"I-ARG0\", \"I-ARG0\", \"I-ARG0\", \"I-ARG0\", \"I-ARG0\", \"I-ARG0\", \"I-ARG0\", \"O\", \"B-V\", \"B-ARG1\", \"I-ARG1\", \"I-ARG1\", \"I-ARG1\", \"I-ARG1\", \"I-ARG1\", \"I-ARG1\", \"I-ARG1\", \"I-ARG1\", \"O\"]}, {\"verb\": \"go\", \"description\": \"[ARG0: Alice , whose husband went jogging every Sunday] , liked to [V: go] [ARG4: to a dancing class] [ARGM-TMP: in the meantime] .\", \"tags\": [\"B-ARG0\", \"I-ARG0\", \"I-ARG0\", \"I-ARG0\", \"I-ARG0\", \"I-ARG0\", \"I-ARG0\", \"I-ARG0\", \"O\", \"O\", \"O\", \"B-V\", \"B-ARG4\", \"I-ARG4\", \"I-ARG4\", \"I-ARG4\", \"B-ARGM-TMP\", \"I-ARGM-TMP\", \"I-ARGM-TMP\", \"O\"]}, {\"verb\": \"dancing\", \"description\": \"Alice , whose husband went jogging every Sunday , liked to go to a [V: dancing] [ARG0: class] in the meantime .\", \"tags\": [\"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"B-V\", \"B-ARG0\", \"O\", \"O\", \"O\", \"O\"]}], \"words\": [\"Alice\", \",\", \"whose\", \"husband\", \"went\", \"jogging\", \"every\", \"Sunday\", \",\", \"liked\", \"to\", \"go\", \"to\", \"a\", \"dancing\", \"class\", \"in\", \"the\", \"meantime\", \".\"]}\n",
            "\n",
            "2021-06-21 06:14:57,587 - INFO - allennlp.models.archival - removing temporary unarchived model dir at /tmp/tmpt3nn8f6m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LqpiCnWFNjb5"
      },
      "source": [
        "Let's focus on the part we are interested in and see if the model finds the predicate. It did! It found the verb \"liked\" as shown in this excerpt of the raw output.\n",
        "\n",
        "The transformer explains that:\n",
        "- The predicate or verb is \"went\"\n",
        "- \"whose husband\" is the argument\n",
        "- \"jogging\" is another argument related to \"went\"\n",
        "- \"every Sunday\" is a temporal modifier represented in the raw output as\n",
        "[ARGM-TMP: every Sunday]\n",
        "\n",
        "We can see that the verb \"jogging\" was identified and was related to \"whose husband\" with the temporal modifier \"every Sunday.\"\n",
        "\n",
        "The argument describing Alice is a bit long but correct.\n",
        "\n",
        "We can see that the temporal modifier \"in the meantime\" was identified as well. It is quite a performance when we think of the simple sequence + verb input the BERTbased model was trained with.\n",
        "\n",
        "Finally, the transformer identifies the last verb, \"dancing,\" as being related to \"class\"."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iMVVRN93OVos"
      },
      "source": [
        "###Sample 5"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hog7HwIHzdm8"
      },
      "source": [
        "Sample 5 does not repeat a verb several times. However, Sample 5 contains a word\n",
        "that can have multiple functions and meanings. It goes beyond polysemy since\n",
        "the word \"round\" can have both different meanings and grammatical functions.\n",
        "The word \"round\" can be a noun, an adjective, an adverb, a transitive verb, or an intransitive verb.\n",
        "\n",
        "As a transitive or intransitive verb, \"round\" can mean to attain perfection or\n",
        "completion. In this sense, \"round\" can be used with \"off.\"\n",
        "\n",
        "The following sentence uses \"round\" in the past tense:\n",
        "\n",
        "```The bright sun, the blue sky, the warm sand, the palm trees, everything round off.```\n",
        "\n",
        "Round is used in a sense \"to bring to perfection\". The best grammatical form would have been \"rounded,\" but the transformer found the right verb, and the sentence sounds rather poetic."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6NFVmvYtzguX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7c2adcd8-732d-4e7b-c327-4df2d2e668dd"
      },
      "source": [
        "!echo '{\"sentence\": \"The bright sun, the blue sky, the warm sand, the palm trees, everything round off.\"}' | \\\n",
        "allennlp predict https://storage.googleapis.com/allennlp-public-models/bert-base-srl-2020.03.24.tar.gz -"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "input 0:  {\"sentence\": \"The bright sun, the blue sky, the warm sand, the palm trees, everything round off.\"}\n",
            "prediction:  {\"verbs\": [], \"words\": [\"The\", \"bright\", \"sun\", \",\", \"the\", \"blue\", \"sky\", \",\", \"the\", \"warm\", \"sand\", \",\", \"the\", \"palm\", \"trees\", \",\", \"everything\", \"round\", \"off\", \".\"]}\n",
            "\n",
            "2021-06-21 06:22:32,844 - INFO - allennlp.models.archival - removing temporary unarchived model dir at /tmp/tmpkqk6_nyt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jLqcOkXLPENh"
      },
      "source": [
        "The output shows no verbs. The transformer did not identify the predicate. In fact, it found no verbs at all.\n",
        "\n",
        "Since we like our BERT-based transformer, we will be kind to it. Let's change the sentence from the past tense to the present tense.\n",
        "\n",
        "```The bright sun, the blue sky, the warm sand, the palm trees, everything rounds off.```\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T9UCG-qN018X",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "30f400e8-a52e-4e5e-f051-45db4881c23a"
      },
      "source": [
        "!echo '{\"sentence\": \"The bright sun, the blue sky, the warm sand, the palm trees, everything rounds off.\"}' | \\\n",
        "allennlp predict https://storage.googleapis.com/allennlp-public-models/bert-base-srl-2020.03.24.tar.gz -"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "input 0:  {\"sentence\": \"The bright sun, the blue sky, the warm sand, the palm trees, everything rounds off.\"}\n",
            "prediction:  {\"verbs\": [{\"verb\": \"rounds\", \"description\": \"[ARG1: The bright sun , the blue sky , the warm sand , the palm trees] , [R-ARG1: everything] [V: rounds] off .\", \"tags\": [\"B-ARG1\", \"I-ARG1\", \"I-ARG1\", \"I-ARG1\", \"I-ARG1\", \"I-ARG1\", \"I-ARG1\", \"I-ARG1\", \"I-ARG1\", \"I-ARG1\", \"I-ARG1\", \"I-ARG1\", \"I-ARG1\", \"I-ARG1\", \"I-ARG1\", \"O\", \"B-R-ARG1\", \"B-V\", \"O\", \"O\"]}], \"words\": [\"The\", \"bright\", \"sun\", \",\", \"the\", \"blue\", \"sky\", \",\", \"the\", \"warm\", \"sand\", \",\", \"the\", \"palm\", \"trees\", \",\", \"everything\", \"rounds\", \"off\", \".\"]}\n",
            "\n",
            "2021-06-21 06:26:40,005 - INFO - allennlp.models.archival - removing temporary unarchived model dir at /tmp/tmpp1pcwdjm\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wc9bQ_F5QGHL"
      },
      "source": [
        "The raw output shows that the predicate was found.\n",
        "\n",
        "Our BERT-based transformer did well because the word \"round\" can be found as\n",
        "\"rounds\" in its plural form.\n",
        "\n",
        "The BERT model initially failed to produce the result we expected. But with a little help from its friends, all ended well for this sample."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f3zP7RTCQU7Q"
      },
      "source": [
        "###Sample 6"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cBrxUvrL3Sp4"
      },
      "source": [
        "Sample 6 takes a word we often think is just a noun. However, more words than\n",
        "we suspect can be both nouns and verbs. \"To ice\" is a verb used in hockey to shoot a \"puck\" all the way across the rink and beyond the goal line of an opponent. The \"puck\" is the disk used in hockey.\n",
        "\n",
        "A hockey coach can start the day by telling a team to train icing pucks. We then can obtain the imperative sentence when the coach yells:\n",
        "\n",
        "```Now, ice pucks guys!```\n",
        "\n",
        "Note that \"guys\" can mean \"persons\" regardless of their sex."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rp77Vazw3QY8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bf74896e-1f60-4e2b-cfa2-a864b65d51a5"
      },
      "source": [
        "!echo '{\"sentence\": \"Now, ice pucks guys!\"}' | \\\n",
        "allennlp predict https://storage.googleapis.com/allennlp-public-models/bert-base-srl-2020.03.24.tar.gz -"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "input 0:  {\"sentence\": \"Now, ice pucks guys!\"}\n",
            "prediction:  {\"verbs\": [], \"words\": [\"Now\", \",\", \"ice\", \"pucks\", \"guys\", \"!\"]}\n",
            "\n",
            "2021-06-21 06:34:18,257 - INFO - allennlp.models.archival - removing temporary unarchived model dir at /tmp/tmprznv5ksm\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5KwnAnSMR3zX"
      },
      "source": [
        "Game over! We can see that transformers have made tremendous progress, but there\n",
        "is still a lot of room for developers to improve the models. Humans are still in the game!"
      ]
    }
  ]
}